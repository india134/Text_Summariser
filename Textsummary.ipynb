{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bebd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=pd.read_csv('CNNtrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=pd.read_csv('CNNtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee25a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e7947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming traindata and testdata are your original dataframes\n",
    "# Select 5000 random rows for training and 3000 for testing\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "train_sample = traindata.sample(n=5000, random_state=42)\n",
    "test_sample = testdata.sample(n=1000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96656c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_sample.reset_index(drop=True)\n",
    "test_sample = test_sample.reset_index(drop=True)\n",
    "\n",
    "# Check the first few rows of each sample to confirm\n",
    "print(train_sample.head())\n",
    "print(test_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430eb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained T5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb01ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, tokenizer, max_input_length=512, max_output_length=150):\n",
    "    # Add \"summarize:\" prefix to each article for T5’s text-to-text format\n",
    "    inputs = [\"summarize: \" + text for text in data[\"article\"]]\n",
    "    targets = list(data[\"highlights\"])\n",
    "    \n",
    "    # Tokenize inputs and targets\n",
    "    input_encodings = tokenizer(inputs, truncation=True, padding=True, max_length=max_input_length, return_tensors=\"pt\")\n",
    "    target_encodings = tokenizer(targets, truncation=True, padding=True, max_length=max_output_length, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return input_encodings, target_encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_labels = preprocess_data(train_sample, tokenizer)\n",
    "test_inputs, test_labels = preprocess_data(test_sample, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de21d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4470d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b733401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testing datasets\n",
    "train_dataset = SummarizationDataset(train_inputs, train_labels)\n",
    "test_dataset = SummarizationDataset(test_inputs, test_labels)\n",
    "\n",
    "# Define batch size (you can adjust it based on your available memory and GPU capacity)\n",
    "batch_size = 4\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88fe3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop (you should be able to run this now)\n",
    "# Set the number of epochs\n",
    "num_epochs = 3  # You can adjust this number as needed\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        # Training code here...\n",
    "        pass  # Replace with actual training steps as discussed earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c54c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs\n",
    "num_epochs = 1  # You can adjust this based on your requirements\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0  # Initialize loss for this epoch\n",
    "\n",
    "    # Iterate over each batch\n",
    "    for batch in train_loader:\n",
    "        # Move batch data to the device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Zero out gradients from the previous step\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: Get model outputs and compute loss\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass: Calculate gradients and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the loss for this batch\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Calculate and print average loss for this epoch\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "rouge1, rouge2, rougeL = 0, 0, 0\n",
    "num_samples = len(generated_summaries)\n",
    "\n",
    "for gen_summary, ref_summary in zip(generated_summaries, reference_summaries):\n",
    "    scores = scorer.score(ref_summary, gen_summary)\n",
    "    rouge1 += scores['rouge1'].fmeasure\n",
    "    rouge2 += scores['rouge2'].fmeasure\n",
    "    rougeL += scores['rougeL'].fmeasure\n",
    "\n",
    "# Calculate average ROUGE scores\n",
    "print(f\"Average ROUGE-1: {rouge1 / num_samples:.4f}\")\n",
    "print(f\"Average ROUGE-2: {rouge2 / num_samples:.4f}\")\n",
    "print(f\"Average ROUGE-L: {rougeL / num_samples:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4049828",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summaries = []\n",
    "reference_summaries = test_sample['highlights'].tolist()  # Assuming 'highlights' is the column for reference summaries\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Generate summaries for each batch in the test set\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move batch data to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        # Generate summary using the model\n",
    "        generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=150, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        # Decode the generated summaries\n",
    "        batch_summaries = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "        generated_summaries.extend(batch_summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fc18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb45095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         id  \\\n",
      "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
      "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
      "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
      "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
      "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
      "\n",
      "                                             article  \\\n",
      "0  Ever noticed how plane seats appear to be gett...   \n",
      "1  A drunk teenage boy had to be rescued by secur...   \n",
      "2  Dougie Freedman is on the verge of agreeing a ...   \n",
      "3  Liverpool target Neto is also wanted by PSG an...   \n",
      "4  Bruce Jenner will break his silence in a two-h...   \n",
      "\n",
      "                                          highlights  \n",
      "0  Experts question if  packed out planes are put...  \n",
      "1  Drunk teenage boy climbed into lion enclosure ...  \n",
      "2  Nottingham Forest are close to extending Dougi...  \n",
      "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
      "4  Tell-all interview with the reality TV star, 6...  \n",
      "                                         id  \\\n",
      "0  f00ae3c3929d829cd469ba4f229cc613b0766203   \n",
      "1  9e451f79499e5c784222b3f237c6ae4829849d79   \n",
      "2  dae58055bd50598b93a230aa3a58e0d2f519b536   \n",
      "3  c05bda9b387ec8ae43803170b6f59b4b82505db9   \n",
      "4  5c7493c6f28cfd58aa7b5f0e486e611307b4126d   \n",
      "\n",
      "                                             article  \\\n",
      "0  Comedian Jenny Eclair travelled with her other...   \n",
      "1  A woman of Arab and Jewish descent who was str...   \n",
      "2  World No 1 Novak Djokovic has apologised to th...   \n",
      "3  (CNN)ISIS on Wednesday released more than 200 ...   \n",
      "4  Hillary Clinton’s security detail arrived at a...   \n",
      "\n",
      "                                          highlights  \n",
      "0  The comedian stayed with Flavours who offer a ...  \n",
      "1  The federal government will give Shoshana Hebs...  \n",
      "2  Novak Djokovic beat Andy Murray 7-6 4-6 6-0 in...  \n",
      "3  Most of those released were women and children...  \n",
      "4  Second modified, armored van spotted near Des ...  \n",
      "                                         id  \\\n",
      "0  f00ae3c3929d829cd469ba4f229cc613b0766203   \n",
      "1  9e451f79499e5c784222b3f237c6ae4829849d79   \n",
      "2  dae58055bd50598b93a230aa3a58e0d2f519b536   \n",
      "3  c05bda9b387ec8ae43803170b6f59b4b82505db9   \n",
      "4  5c7493c6f28cfd58aa7b5f0e486e611307b4126d   \n",
      "\n",
      "                                             article  \\\n",
      "0  Comedian Jenny Eclair travelled with her other...   \n",
      "1  A woman of Arab and Jewish descent who was str...   \n",
      "2  World No 1 Novak Djokovic has apologised to th...   \n",
      "3  (CNN)ISIS on Wednesday released more than 200 ...   \n",
      "4  Hillary Clinton’s security detail arrived at a...   \n",
      "\n",
      "                                          highlights  \n",
      "0  The comedian stayed with Flavours who offer a ...  \n",
      "1  The federal government will give Shoshana Hebs...  \n",
      "2  Novak Djokovic beat Andy Murray 7-6 4-6 6-0 in...  \n",
      "3  Most of those released were women and children...  \n",
      "4  Second modified, armored van spotted near Des ...  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# Replace 'path_to_csv' with the actual path to your dataset\n",
    "data = pd.read_csv('CNNtest.csv')\n",
    "\n",
    "# Display dataset structure\n",
    "print(data.head())\n",
    "\n",
    "# Select a smaller sample (e.g., 5000 rows for training and 2000 for testing)\n",
    "train_data = data.sample(n=5000, random_state=42)\n",
    "test_data = data.sample(n=2000, random_state=42)\n",
    "\n",
    "# Reset indices for both\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display sample structure\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acce13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input_length=512, max_target_length=150):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        article = str(self.data.iloc[index]['article'])\n",
    "        summary = str(self.data.iloc[index]['highlights'])\n",
    "\n",
    "        # Tokenize input (article) and output (summary)\n",
    "        input_encoding = self.tokenizer(\n",
    "            article,\n",
    "            max_length=self.max_input_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        target_encoding = self.tokenizer(\n",
    "            summary,\n",
    "            max_length=self.max_target_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Return tokenized input and output\n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "            'labels': target_encoding['input_ids'].squeeze()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794188ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Initialize T5 tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = SummarizationDataset(train_data, tokenizer)\n",
    "test_dataset = SummarizationDataset(test_data, tokenizer)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86cf573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained T5 model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21f2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, optimizer, num_epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            # Move data to the device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33cc5797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5661949213981627\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 1 epoch as a starting point\n",
    "train_model(model, train_loader, optimizer, num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d22b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1: 0.3450\n",
      "Average ROUGE-2: 0.1588\n",
      "Average ROUGE-L: 0.2436\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Generate summaries for the test dataset\n",
    "model.eval()\n",
    "generated_summaries = []\n",
    "reference_summaries = test_data['highlights'].tolist()  # Reference summaries (ground truth)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        # Generate summaries\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=150, num_beams=4, early_stopping=True)\n",
    "        decoded_summaries = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in outputs]\n",
    "        generated_summaries.extend(decoded_summaries)\n",
    "\n",
    "# Initialize ROUGE scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "rouge1, rouge2, rougeL = 0, 0, 0\n",
    "num_samples = len(generated_summaries)\n",
    "\n",
    "for gen_summary, ref_summary in zip(generated_summaries, reference_summaries):\n",
    "    scores = scorer.score(ref_summary, gen_summary)\n",
    "    rouge1 += scores['rouge1'].fmeasure\n",
    "    rouge2 += scores['rouge2'].fmeasure\n",
    "    rougeL += scores['rougeL'].fmeasure\n",
    "\n",
    "# Average scores\n",
    "rouge1_avg = rouge1 / num_samples\n",
    "rouge2_avg = rouge2 / num_samples\n",
    "rougeL_avg = rougeL / num_samples\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average ROUGE-1: {rouge1_avg:.4f}\")\n",
    "print(f\"Average ROUGE-2: {rouge2_avg:.4f}\")\n",
    "print(f\"Average ROUGE-L: {rougeL_avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23b7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
